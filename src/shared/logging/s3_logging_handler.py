# s3_logging_handler.py - VERSÃƒO CORRIGIDA
import logging
import boto3
import json
from datetime import datetime, timezone
from threading import Lock, Timer
from collections import deque
from botocore.client import Config
import os

class S3BufferedHandler(logging.Handler):
    """
    Handler otimizado que acumula logs em buffer e envia para S3 em lotes

    Analogia: Como um caminhÃ£o de lixo inteligente que:
    - Coleta resÃ­duos de vÃ¡rias casas (buffer)
    - Vai ao aterro quando estÃ¡ cheio OU no horÃ¡rio programado
    - Tem GPS para nÃ£o se perder (retry logic)
    - Tem backup se o aterro estiver fechado (fallback local)
    """

    def __init__(self,
                 bucket_name: str,
                 app_name: str,
                 s3_key_prefix: str = "logs",
                 aws_access_key_id: str | None = None,
                 aws_secret_access_key: str | None = None,
                 aws_region: str = "us-east-1",
                 buffer_size: int = 100,
                 flush_interval: int = 300,  # 5 minutos
                 max_retry_attempts: int = 3,
                 level=logging.NOTSET):

        super().__init__(level)

        self.bucket_name = bucket_name
        self.app_name = app_name
        self.s3_key_prefix = s3_key_prefix
        self.buffer_size = buffer_size
        self.flush_interval = flush_interval
        self.max_retry_attempts = max_retry_attempts

        # Buffer thread-safe para armazenar logs
        self.buffer = deque()
        self.buffer_lock = Lock()
        self.sending_threads = [] # Para rastrear threads de envio e aguardar sua conclusÃ£o

        # EstatÃ­sticas para monitoramento
        self.stats = {
            'logs_buffered': 0,
            'logs_sent': 0,
            'batches_sent': 0,
            'errors': 0,
            'last_flush': None
        }

        # Cliente S3 com configuraÃ§Ã£o otimizada
        session = boto3.Session(
            aws_access_key_id=aws_access_key_id or os.getenv('AWS_ACCESS_KEY_ID'),
            aws_secret_access_key=aws_secret_access_key or os.getenv('AWS_SECRET_ACCESS_KEY'),
            region_name=os.getenv('AWS_DEFAULT_REGION') or aws_region
        )

        self.s3_client = session.client(
            's3',
            config=Config(
                retries={'max_attempts': 2, 'mode': 'adaptive'},
                max_pool_connections=10
            )
        )

        # InformaÃ§Ãµes da sessÃ£o
        self.session_id = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        self.instance_id = os.getenv('RENDER_INSTANCE_ID', 'local')[:8]

        # Timer para flush automÃ¡tico
        self.timer = None
        self._setup_auto_flush()

        # Flag para indicar se estÃ¡ sendo fechado
        self._closing = False

    def emit(self, record):
        """Adiciona log ao buffer de forma thread-safe"""
        if self._closing:
            return

        try:
            # Formata a mensagem com informaÃ§Ãµes extras para Estoque RÃ¡pido
            log_entry = {
                'timestamp': datetime.fromtimestamp(record.created, tz=timezone.utc).isoformat(),
                'level': record.levelname,
                'logger': record.name,
                'message': self.format(record),
                'module': getattr(record, 'module', ''),
                'function': getattr(record, 'funcName', ''),
                'line': getattr(record, 'lineno', 0),
                'thread_name': getattr(record, 'threadName', ''),
                'process_id': os.getpid(),
                'session_id': self.session_id,
                'instance_id': self.instance_id,
                # InformaÃ§Ãµes extras se disponÃ­veis
                'pathname': getattr(record, 'pathname', ''),
                'exc_info': self.format(record) if record.exc_info else None
            }

            with self.buffer_lock:
                self.buffer.append(log_entry)
                self.stats['logs_buffered'] += 1

                # Flush automÃ¡tico se buffer estiver cheio
                if len(self.buffer) >= self.buffer_size:
                    self._flush_buffer_internal()

        except Exception as e:
            self.stats['errors'] += 1
            self.handleError(record)

    def _flush_buffer_internal(self):
        """Flush interno (jÃ¡ dentro do lock)"""
        if not self.buffer or self._closing:
            return

        try:
            # Prepara o lote para envio
            logs_to_send = list(self.buffer)
            self.buffer.clear()

            # Envia em thread separada para nÃ£o bloquear
            from threading import Thread # Importa aqui para evitar dependÃªncia circular se Thread for usado em outras partes
            thread = Thread(target=self._send_to_s3, args=(logs_to_send,))
            thread.daemon = True
            self.sending_threads.append(thread) # Adiciona Ã  lista antes de iniciar
            thread.start()

        except Exception as e:
            self.stats['errors'] += 1
            print(f"Erro no flush interno: {e}")

    def _send_to_s3(self, logs_to_send):
        """Envia logs para S3 com retry logic"""
        if not logs_to_send:
            return

        for attempt in range(self.max_retry_attempts):
            try:
                # Cria o nome do arquivo com informaÃ§Ãµes detalhadas
                timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S_%f")[:-3]

                # O log serÃ¡ salvo na estrutura: estoquerapido/ > logs/ > 202506/
                # Para logs > YYYY > MM > DD/ Use: f"{datetime.now(timezone.utc).strftime('%Y/%m/%d')}/" para separar Ano, mÃªs e dia em pastas diferentes
                s3_key = (f"{self.s3_key_prefix}/"
                         f"{datetime.now(timezone.utc).strftime('%Y%m')}/"
                         f"estoque_rapido_{self.instance_id}_{timestamp}.jsonl")

                # Prepara o conteÃºdo (JSON Lines format para eficiÃªncia)
                log_lines = []
                for log_entry in logs_to_send:
                    log_lines.append(json.dumps(log_entry, ensure_ascii=False, separators=(',', ':')))

                content = '\n'.join(log_lines)

                # Metadados do arquivo
                metadata = {
                    'session_id': self.session_id,
                    'instance_id': self.instance_id,
                    'log_count': str(len(logs_to_send)),
                    'app_name': self.app_name,
                    'environment': 'production' if os.getenv('RENDER') else 'development'
                }

                # Upload para S3
                self.s3_client.put_object(
                    Bucket=self.bucket_name,
                    Key=s3_key,
                    Body=content.encode('utf-8'),
                    ContentType='application/x-jsonlines',
                    Metadata=metadata
                )

                # Atualiza estatÃ­sticas
                self.stats['logs_sent'] += len(logs_to_send)
                self.stats['batches_sent'] += 1
                self.stats['last_flush'] = datetime.now(timezone.utc).isoformat()

                print(f"ðŸ“¤ Logs enviados para S3: {len(logs_to_send)} entradas -> {s3_key}")
                return  # Sucesso, sai do loop de retry

            except Exception as e:
                self.stats['errors'] += 1
                if attempt < self.max_retry_attempts - 1:
                    wait_time = (2 ** attempt) * 1  # Backoff exponencial: 1s, 2s, 4s
                    print(f"âŒ Erro ao enviar logs (tentativa {attempt + 1}): {e}")
                    print(f"   Tentando novamente em {wait_time}s...")
                    import time
                    time.sleep(wait_time)
                else:
                    print(f"âŒ Falha definitiva ao enviar logs apÃ³s {self.max_retry_attempts} tentativas: {e}")
                    # TODO: Implementar fallback local se necessÃ¡rio

    def _setup_auto_flush(self):
        """Configura o timer para flush automÃ¡tico"""
        def auto_flush():
            if not self._closing and self.buffer:
                with self.buffer_lock:
                    self._flush_buffer_internal()

            # Reagenda o prÃ³ximo flush
            if not self._closing:
                self.timer = Timer(self.flush_interval, auto_flush)
                self.timer.daemon = True
                self.timer.start()

        self.timer = Timer(self.flush_interval, auto_flush)
        self.timer.daemon = True
        self.timer.start()

    def flush(self):
        """ForÃ§a o envio de todos os logs do buffer"""
        with self.buffer_lock:
            self._flush_buffer_internal()

        # Aguarda um pouco para permitir que a thread termine
        import time
        time.sleep(1)

    def close(self):
        """Finaliza o handler enviando logs restantes"""
        self._closing = True

        if self.timer:
            self.timer.cancel()

        # Flush final
        self.flush()

        # Aguarda todas as threads de envio concluÃ­rem
        for thread in list(self.sending_threads): # Itera sobre uma cÃ³pia, pois a lista pode ser modificada
            if thread.is_alive():
                try:
                    thread.join(timeout=5) # Espera atÃ© 5 segundos para cada thread
                except RuntimeError: # A thread pode jÃ¡ ter terminado
                    pass
            with self.buffer_lock: # Adquire o lock para remover com seguranÃ§a da lista compartilhada
                if thread in self.sending_threads:
                    self.sending_threads.remove(thread)

        final_logger = logging.getLogger(__name__)
        # Log das estatÃ­sticas finais
        final_logger.info("ðŸ“Š EstatÃ­sticas do S3Handler:")
        final_logger.info(f"   Logs processados: {self.stats['logs_buffered']}")
        final_logger.info(f"   Logs enviados: {self.stats['logs_sent']}")
        final_logger.info(f"   Lotes enviados: {self.stats['batches_sent']}")
        final_logger.info(f"   Erros: {self.stats['errors']}")
        super().close()

    def get_stats(self):
        """Retorna estatÃ­sticas do handler"""
        return self.stats.copy()


class EstoqueRapidoLogConfig:
    """
    ConfiguraÃ§Ã£o de logging hÃ­brida otimizada para Estoque RÃ¡pido

    Analogia: Como ter um caderno de rascunho (local) e um arquivo definitivo (S3)
    - Desenvolvimento: arquivo local para debug rÃ¡pido
    - ProduÃ§Ã£o: S3 com buffer inteligente para eficiÃªncia
    """

    def __init__(self,
                 log_level=None,  # Auto-detecta baseado no ambiente
                 use_s3=None,     # Auto-detecta baseado no ambiente
                 bucket_name=None,
                 app_name=None):

        # Auto-detecÃ§Ã£o do ambiente
        self.is_production = os.getenv('RENDER', '').lower() == 'true'

        # ConfiguraÃ§Ãµes inteligentes baseadas no ambiente
        if log_level is None:
            log_level = logging.INFO if self.is_production else logging.DEBUG

        if use_s3 is None:
            use_s3 = self.is_production

        if bucket_name is None:
            bucket_name = os.getenv('AWS_S3_BUCKET_NAME')

        if app_name is None:
            app_name = os.getenv('AWS_S3_APP_NAME')

        self.use_s3 = use_s3 and bucket_name
        self.s3_handler = None

        # Formatter otimizado para Estoque RÃ¡pido
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - [%(levelname)s] - %(funcName)s:%(lineno)d - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )

        # Limpa handlers existentes para evitar duplicaÃ§Ã£o
        root_logger = logging.getLogger()
        root_logger.handlers.clear()
        root_logger.setLevel(logging.DEBUG)

        # Handler para arquivo local (desenvolvimento)
        if not self.is_production:
            self._setup_local_handler(root_logger, formatter, log_level)

        # Handler para S3 (produÃ§Ã£o)
        if self.use_s3:
            self._setup_s3_handler(root_logger, formatter, bucket_name, app_name, log_level)

        # Handler para console (sempre presente)
        self._setup_console_handler(root_logger, formatter)

        # ConfiguraÃ§Ãµes especÃ­ficas para bibliotecas externas
        self._setup_third_party_loggers()

        # Configurar graceful shutdown
        self._setup_graceful_shutdown()

        # Log de inicializaÃ§Ã£o
        logger = logging.getLogger(__name__)
        environment = "PRODUÃ‡ÃƒO (Render)" if self.is_production else "DESENVOLVIMENTO"
        logger.info(f"Sistema de logging inicializado - Ambiente: {environment}")
        if self.use_s3:
            logger.info(f"Logs sendo enviados para S3: {bucket_name}")

    def _setup_local_handler(self, root_logger, formatter, log_level):
        """Configura handler para arquivo local (desenvolvimento)"""
        from logging.handlers import RotatingFileHandler

        try:
            # CORREÃ‡ÃƒO: Import seguro do find_project_root
            try:
                from src.shared.utils.find_project_path import find_project_root
                project_root = find_project_root(__file__)
            except ImportError:
                # Fallback se nÃ£o encontrar o mÃ³dulo
                project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

            log_dir = os.path.join(project_root, 'logs')
            os.makedirs(log_dir, exist_ok=True)

            log_file = os.path.join(log_dir, "estoque_rapido.log")

            file_handler = RotatingFileHandler(
                log_file,
                maxBytes=10485760,  # 10MB
                backupCount=10,     # Manter 10 arquivos de backup
                encoding='utf-8'
            )
            file_handler.setFormatter(formatter)
            file_handler.setLevel(log_level)
            root_logger.addHandler(file_handler)

            print(f"âœ“ Log local configurado: {log_file}")

        except Exception as e:
            print(f"âœ— Erro ao configurar handler local: {e}")

    def _setup_s3_handler(self, root_logger, formatter, bucket_name, app_name, log_level):
        """Configura handler para S3 com buffer otimizado"""
        try:
            # Torna o buffer e o intervalo configurÃ¡veis via variÃ¡veis de ambiente
            buffer_size = int(os.getenv('AWS_S3_LOG_BUFFER_SIZE', '200'))
            flush_interval = int(os.getenv('AWS_S3_LOG_FLUSH_INTERVAL', '600')) # 10 minutos

            self.s3_handler = S3BufferedHandler(
                bucket_name=bucket_name,
                app_name=app_name,
                s3_key_prefix=f"{app_name}/logs",
                # buffer_size=100,     # Buffer maior para produÃ§Ã£o
                # flush_interval=300,  # 5 minutos
                buffer_size=buffer_size,
                flush_interval=flush_interval,
                level=log_level
            )
            self.s3_handler.setFormatter(formatter)
            root_logger.addHandler(self.s3_handler)

            print(f"âœ“ Log S3 configurado: {bucket_name}/{app_name}/logs/")

        except Exception as e:
            print(f"âœ— Erro ao configurar handler S3: {e}")
            self.s3_handler = None

    def _setup_console_handler(self, root_logger, formatter):
        """Configura handler para console"""
        import sys
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(formatter)

        # No desenvolvimento: tudo no console
        # Na produÃ§Ã£o: apenas WARNING e acima
        console_level = logging.DEBUG if not self.is_production else logging.WARNING
        console_handler.setLevel(console_level)

        root_logger.addHandler(console_handler)

    def _setup_third_party_loggers(self):
        """Configura loggers de bibliotecas externas"""
        # ConfiguraÃ§Ãµes especÃ­ficas para diferentes bibliotecas
        logger_configs = {
            "uvicorn": logging.INFO,
            "uvicorn.access": logging.WARNING,  # Reduz ruÃ­do de acesso
            "uvicorn.error": logging.ERROR,
            "websockets": logging.WARNING,      # Reduz ruÃ­do de websockets
            "boto3": logging.WARNING,           # AWS SDK
            "botocore": logging.WARNING,        # AWS Core
            "flet": logging.INFO,               # Flet framework
            "flet_core": logging.WARNING,       # Flet core components
            # Ajuste especÃ­fico para flet_web.fastapi
            # Em produÃ§Ã£o, queremos menos verbosidade, focando em warnings/errors.
            # Em desenvolvimento, INFO pode ser Ãºtil para entender o fluxo.
            "flet_web.fastapi": logging.WARNING if self.is_production else logging.INFO,
        }

        for logger_name, level in logger_configs.items():
            logger = logging.getLogger(logger_name)
            logger.setLevel(level)
            # Garante que os handlers configurados no root logger sejam utilizados,
            # a menos que um handler especÃ­fico seja adicionado a este logger.
            # No seu caso, como vocÃª limpa e adiciona handlers ao root, True Ã© o ideal.
            logger.propagate = True

    def _setup_graceful_shutdown(self):
        """Configura shutdown gracioso para garantir envio dos logs"""
        import atexit
        import signal
        import sys

        def cleanup():
            if self.s3_handler:
                print("Enviando logs finais para S3...")
                self.s3_handler.flush()
                self.s3_handler.close()

        # Registra cleanup para diferentes cenÃ¡rios de shutdown
        atexit.register(cleanup)

        def signal_handler(signum, frame):
            print(f"Recebido sinal {signum}, fazendo cleanup...")
            cleanup()
            sys.exit(0)

        signal.signal(signal.SIGTERM, signal_handler)
        signal.signal(signal.SIGINT, signal_handler)


# ===== FUNÃ‡ÃƒO PRINCIPAL PARA USAR NO SEU PROJETO =====
def setup_estoque_rapido_logging():
    """
    FunÃ§Ã£o para inicializar o sistema de logging do Estoque RÃ¡pido

    Uso:
    - Desenvolvimento: arquivo local + console detalhado
    - ProduÃ§Ã£o: S3 com buffer + console resumido

    Returns:
        logging.Logger: Logger configurado e pronto para uso
    """

    # Verifica se as variÃ¡veis necessÃ¡rias estÃ£o configuradas
    if os.getenv('RENDER') and not os.getenv('AWS_S3_BUCKET_NAME'):
        print("âš ï¸  AVISO: Rodando no Render mas AWS_S3_BUCKET_NAME nÃ£o configurado!")
        print("   Configure as variÃ¡veis de ambiente para logging em S3")

    # Inicializa a configuraÃ§Ã£o
    log_config = EstoqueRapidoLogConfig()

    # Retorna um logger pronto para uso
    return logging.getLogger("estoque_rapido")


# ===== FUNÃ‡Ã•ES AUXILIARES PARA PÃGINA DE ADMINISTRAÃ‡ÃƒO =====
def get_s3_logging_stats():
    """
    Retorna estatÃ­sticas do sistema de logging S3

    Returns:
        dict: EstatÃ­sticas atuais do handler S3
    """
    root_logger = logging.getLogger()

    for handler in root_logger.handlers:
        if isinstance(handler, S3BufferedHandler):
            stats = handler.get_stats()
            stats['buffer_current_size'] = len(handler.buffer)
            stats['buffer_max_size'] = handler.buffer_size
            stats['flush_interval'] = handler.flush_interval
            return stats

    return {'error': 'S3Handler nÃ£o encontrado'}


def force_s3_logging_flush():
    """
    ForÃ§a o flush imediato de todos os logs para S3

    Returns:
        dict: Resultado da operaÃ§Ã£o
    """
    root_logger = logging.getLogger()

    for handler in root_logger.handlers:
        if isinstance(handler, S3BufferedHandler):
            try:
                handler.flush()
                return {'success': True, 'message': 'Flush executado com sucesso'}
            except Exception as e:
                return {'success': False, 'error': str(e)}

    return {'success': False, 'error': 'S3Handler nÃ£o encontrado'}
